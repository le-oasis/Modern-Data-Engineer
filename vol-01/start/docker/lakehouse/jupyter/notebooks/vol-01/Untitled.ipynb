{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f2a4e1-dd47-4e5a-8808-119d7de8802d",
   "metadata": {},
   "source": [
    "# Read & Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fee555-dff7-47fd-b797-18d1a0e567c1",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4deb3b74-0293-4d5c-971f-7c3b288860b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark import SQLContext\n",
    "import os \n",
    "from delta.tables import * \n",
    "from delta.tables import DeltaTable \n",
    "import hashlib \n",
    "import datetime\n",
    "import urllib.request \n",
    "import json \n",
    "from datetime import timedelta, date\n",
    "from itertools import islice \n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e9f3f-a7b9-4c27-b8bd-22c75bf9ba89",
   "metadata": {},
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25754318-5c5d-4856-abaa-4f8923c1cbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# create a Spark Session \n",
    "from pyspark.sql import SparkSession \n",
    "\n",
    "\n",
    "# Initiate Spark Session \n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName(\"Read_&_Analyze\") \\\n",
    "                    .config(\"spark.driver.extraClassPath\", \"/home/jovyan/work/jars/*\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1319d9-33c8-44bc-a7e9-c9d06b2df845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://myjupyter:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Read_&_Analyze</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbe68e1ee90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# details of the session\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd4864-8144-4b71-8fb5-327435b505e0",
   "metadata": {},
   "source": [
    "### Read a Plain Text File - Schema Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a23e700-01e8-46a1-ba00-e8bbc35a5b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       name|roast|\n",
      "+-----------+-----+\n",
      "|    folgers| 10.0|\n",
      "|      yuban| 10.0|\n",
      "|  nespresso| 10.0|\n",
      "|     ritual|  4.0|\n",
      "|four barrel|  5.0|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the schema for your DataFrame (assuming \"name\" and \"roast\" are your column names)\n",
    "from pyspark.sql.types import *\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"roast\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Read the CSV file and specify the schema and header options\n",
    "coffee_sdf = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .schema(schema) \\\n",
    "    .load(input_path)\n",
    "\n",
    "# Show the data\n",
    "coffee_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59d4e228-ea7c-4562-8196-b4297b455e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- roast: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the schema \n",
    "coffee_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9a2d1a-b9dc-46b9-9ff8-eba365d4ca2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907e84a-dc73-47f4-b05b-c3a92cfc5227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d98afb1c-a6fa-4125-a8d7-349b9a95f647",
   "metadata": {},
   "source": [
    "creating a sql view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69f46080-23f3-4677-b1ec-39ba009f5745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       name|roast|\n",
      "+-----------+-----+\n",
      "|  nespresso| 10.0|\n",
      "|      yuban| 10.0|\n",
      "|    folgers| 10.0|\n",
      "|four barrel|  5.0|\n",
      "|     ritual|  4.0|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a view for the DataFrame\n",
    "coffee_sdf.createOrReplaceTempView(\"coffee\")\n",
    "\n",
    "# Query the view\n",
    "spark.sql(\"SELECT * FROM coffee ORDER BY roast desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c00fa-a150-4fc6-a4b4-ec733fe8948d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95305470-c2f0-4067-b02c-a2fd7e4d40a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+\n",
      "|col_name|data_type|comment|\n",
      "+--------+---------+-------+\n",
      "|    name|   string|   null|\n",
      "|   roast|   double|   null|\n",
      "+--------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## output would show table metadata\n",
    "\n",
    "spark.sql(\"desc coffee\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48436ad2-ed05-442e-ba59-b4c27fa60f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1274fe-f78e-459f-bac5-d6d84e25441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select + coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2627fd90-62d3-4e90-9803-86fe468f2a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|avg_roast|\n",
      "+---------+\n",
      "|      7.8|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the view vertically\n",
    "query = \"\"\"\n",
    "    SELECT avg(roast)\n",
    "    AS avg_roast\n",
    "    FROM coffee\n",
    "    ORDER BY 1 desc\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "925bbb4e-2cd4-446d-8b38-138dadc65534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|min(roast)|avg_roast|\n",
      "+----------+---------+\n",
      "|       4.0|     10.0|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the view vertically\n",
    "query = \"\"\"\n",
    "    SELECT min(roast), max(roast)\n",
    "    AS avg_roast\n",
    "    FROM coffee\n",
    "    ORDER BY 1,2 desc\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba9d12f-6321-473d-9b29-85c8b3267058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
