{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Stared with Spark\n",
    "\n",
    "Welcome to this hands-on training where we will investigate cleaning a dataset using Python and Apache Spark! \n",
    "During this training, we will cover:\n",
    "\n",
    "* Loading a dataset into a Spark DataFrame\n",
    "* Defining a schema for the data\n",
    "* Saving a file as a Parquet file\n",
    "* Projection & Filtering \n",
    "* Modifying, Renaming, and Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The Dataset**\n",
    "\n",
    "The dataset used in this webinar is a set of CSV files named `sf-fire-calls.csv`. The data contains information about calls that came into the San Francisco Fire Department over a number of years. The data contains the following fields:\n",
    "\n",
    "* `CallNumber`: The number of the call\n",
    "* `UnitID`: The ID of the unit that responded to the call\n",
    "* `IncidentNumber`: The number of the incident\n",
    "* `CallType`: The type of call that was made\n",
    "* `CallDate`: The date on which the call was made\n",
    "* `WatchDate`: The date on which the watch was made\n",
    "* `CallFinalDisposition`: The final disposition of the call\n",
    "* `AvailableDtTS`: The timestamp at which the unit was made available\n",
    "* `Address`: The address where the incident occurred\n",
    "* `City`: The city where the incident occurred\n",
    "* `Zipcode`: The zipcode of the city where the incident occurred\n",
    "* `Battalion`: The battalion where the incident occurred\n",
    "* `StationArea`: The station area where the incident occurred\n",
    "* `Box`: The box number where the incident occurred\n",
    "* `OriginalPriority`: The original priority of the call\n",
    "* `Priority`: The priority of the call\n",
    "* `FinalPriority`: The final priority of the call\n",
    "* `ALSUnit`: Whether an ALS unit was called\n",
    "* `CallTypeGroup`: The type of call\n",
    "* `NumAlarms`: The number of alarms\n",
    "* `UnitType`: The unit type that responded\n",
    "* `UnitSequenceInCallDispatch`: The sequence of the unit\n",
    "* `FirePreventionDistrict`: The fire prevention district\n",
    "* `SupervisorDistrict`: The supervisor district\n",
    "* `Neighborhood`: The neighborhood\n",
    "* `Location`: The location of the incident\n",
    "* `RowID`: The row ID\n",
    "* `Delay`: The delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `SparkSession`\n",
    "\n",
    "- `SparkSession` is the entry point to Spark SQL. It is one of the very first objects you create while developing a Spark SQL application.\n",
    "\n",
    "- As a Spark developer, you create a `SparkSession` using the `SparkSession.builder` method (that gives you access to Builder API that you use to configure the session).\n",
    "\n",
    "- In order to work with Spark, we have to first set up a `SparkSession`.\n",
    "\n",
    "- From this point forward, we can interact with Apache Spark using this `spark` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://myjupyter:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>LetSparkWorkForYou</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9baecd94c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a SparkSession and set the extraClassPath configuration\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "    .appName(\"LetSparkWorkForYou\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/home/jovyan/work/jars/*\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Details of the Spark Session\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection \n",
    "\n",
    "- Inspect the data looks like before defining a schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallNumber,UnitID,IncidentNumber,CallType,CallDate,WatchDate,CallFinalDisposition,AvailableDtTm,Address,City,Zipcode,Battalion,StationArea,Box,OriginalPriority,Priority,FinalPriority,ALSUnit,CallTypeGroup,NumAlarms,UnitType,UnitSequenceInCallDispatch,FirePreventionDistrict,SupervisorDistrict,Neighborhood,Location,RowID,Delay\n",
      "20110016,T13,2003235,Structure Fire,01/11/2002,01/10/2002,Other,01/11/2002 01:51:44 AM,2000 Block of CALIFORNIA ST,SF,94109,B04,38,3362,3,3,3,false,\"\",1,TRUCK,2,4,5,Pacific Heights,\"(37.7895840679362, -122.428071912459)\",020110016-T13,2.95\n",
      "20110022,M17,2003241,Medical Incident,01/11/2002,01/10/2002,Other,01/11/2002 03:01:18 AM,0 Block of SILVERVIEW DR,SF,94124,B10,42,6495,3,3,3,true,\"\",1,MEDIC,1,10,10,Bayview Hunters Point,\"(37.7337623673897, -122.396113802632)\",020110022-M17,4.7\n",
      "20110023,M41,2003242,Medical Incident,01/11/2002,01/10/2002,Other,01/11/2002 02:39:50 AM,MARKET ST/MCALLISTER ST,SF,94102,B03,01,1455,3,3,3,true,\"\",1,MEDIC,2,3,6,Tenderloin,\"(37.7811772186856, -122.411699931232)\",020110023-M41,2.4333334\n",
      "20110032,E11,2003250,Vehicle Fire,01/11/2002,01/10/2002,Other,01/11/2002 04:16:46 AM,APPLETON AV/MISSION ST,SF,94110,B06,32,5626,3,3,3,false,\"\",1,ENGINE,1,6,9,Bernal Heights,\"(37.7388432849018, -122.423948785199)\",020110032-E11,1.5\n",
      "20110043,B04,2003259,Alarms,01/11/2002,01/10/2002,Other,01/11/2002 06:01:58 AM,1400 Block of SUTTER ST,SF,94109,B04,03,3223,3,3,3,false,\"\",1,CHIEF,2,4,2,Western Addition,\"(37.7872890372638, -122.424236212664)\",020110043-B04,3.4833333\n",
      "20110072,T08,2003279,Structure Fire,01/11/2002,01/11/2002,Other,01/11/2002 08:03:26 AM,BEALE ST/FOLSOM ST,SF,94105,B03,35,2122,3,3,3,false,\"\",1,TRUCK,2,3,6,Financial District/South Beach,\"(37.7886866619654, -122.392722833778)\",020110072-T08,1.75\n",
      "20110125,E33,2003301,Alarms,01/11/2002,01/11/2002,Other,01/11/2002 09:46:44 AM,0 Block of FARALLONES ST,SF,94112,B09,33,8324,3,3,3,false,\"\",1,ENGINE,2,9,11,Oceanview/Merced/Ingleside,\"(37.7140353531157, -122.454117149916)\",020110125-E33,2.7166667\n",
      "20110130,E36,2003304,Alarms,01/11/2002,01/11/2002,Other,01/11/2002 09:58:53 AM,600 Block of POLK ST,SF,94102,B02,03,3114,3,3,3,false,\"\",1,ENGINE,1,2,6,Tenderloin,\"(37.7826266328595, -122.41915582123)\",020110130-E36,1.7833333\n",
      "20110197,E05,2003343,Medical Incident,01/11/2002,01/11/2002,Other,01/11/2002 12:06:57 PM,1500 Block of WEBSTER ST,SF,94115,B04,05,3513,3,3,3,false,\"\",1,ENGINE,1,4,5,Japantown,\"(37.784958590666, -122.431435274503)\",020110197-E05,1.5166667\n"
     ]
    }
   ],
   "source": [
    "! head /home/jovyan/work/data/sf-fire-calls.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data \n",
    "\n",
    "- Read Data From File\n",
    "\n",
    "### Schema Definition \n",
    "\n",
    "- Define our schema as the file has large volume. Inferring the schema is expensive for large files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Schema\n",
    "fire_schema = StructType([StructField('CallNumber', IntegerType(), True),\n",
    "                    StructField('UnitID', StringType(), True),\n",
    "                    StructField('IncidentNumber', IntegerType(), True),\n",
    "                    StructField('CallType', StringType(), True),\n",
    "                    StructField('CallDate', StringType(), True),\n",
    "                    StructField('WatchDate', StringType(), True),\n",
    "                    StructField('CallFinalDisposition', StringType(), True),\n",
    "                    StructField('AvailableDtTm', StringType(), True),\n",
    "                    StructField('Address', StringType(), True),\n",
    "                    StructField('City', StringType(), True),\n",
    "                    StructField('Zipcode', IntegerType(), True),\n",
    "                    StructField('Battalion', StringType(), True),\n",
    "                    StructField('StationArea', StringType(), True),\n",
    "                    StructField('Box', StringType(), True),\n",
    "                    StructField('OriginalPriority', StringType(), True),\n",
    "                    StructField('Priority', StringType(), True),\n",
    "                    StructField('FinalPriority', IntegerType(), True),\n",
    "                    StructField('ALSUnit', BooleanType(), True),\n",
    "                    StructField('CallTypeGroup', StringType(), True),\n",
    "                    StructField('NumAlarms', IntegerType(), True),\n",
    "                    StructField('UnitType', StringType(), True),\n",
    "                    StructField('UnitSequenceInCallDispatch', IntegerType(), True),\n",
    "                    StructField('FirePreventionDistrict', StringType(), True),\n",
    "                    StructField('SupervisorDistrict', StringType(), True),\n",
    "                    StructField('Neighborhood', StringType(), True),\n",
    "                    StructField('Location', StringType(), True),\n",
    "                    StructField('RowID', StringType(), True),\n",
    "                    StructField('Delay', FloatType(), True)])\n",
    "\n",
    "# file path \n",
    "sr_file = \"/home/jovyan/work/data/sf-fire-calls.csv\"\n",
    "\n",
    "# read into spark \n",
    "fire_df = (spark.read.csv(sr_file, header=True, schema=fire_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[CallNumber: int, UnitID: string, IncidentNumber: int, CallType: string, CallDate: string, WatchDate: string, CallFinalDisposition: string, AvailableDtTm: string, Address: string, City: string, Zipcode: int, Battalion: string, StationArea: string, Box: string, OriginalPriority: string, Priority: string, FinalPriority: int, ALSUnit: boolean, CallTypeGroup: string, NumAlarms: int, UnitType: string, UnitSequenceInCallDispatch: int, FirePreventionDistrict: string, SupervisorDistrict: string, Neighborhood: string, Location: string, RowID: string, Delay: float]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|CallType        |CallDate  |WatchDate |CallFinalDisposition|AvailableDtTm         |Address                    |City|Zipcode|Battalion|StationArea|Box |OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|Neighborhood         |Location                             |RowID        |Delay    |\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+---------+\n",
      "|20110016  |T13   |2003235       |Structure Fire  |01/11/2002|01/10/2002|Other               |01/11/2002 01:51:44 AM|2000 Block of CALIFORNIA ST|SF  |94109  |B04      |38         |3362|3               |3       |3            |false  |null         |1        |TRUCK   |2                         |4                     |5                 |Pacific Heights      |(37.7895840679362, -122.428071912459)|020110016-T13|2.95     |\n",
      "|20110022  |M17   |2003241       |Medical Incident|01/11/2002|01/10/2002|Other               |01/11/2002 03:01:18 AM|0 Block of SILVERVIEW DR   |SF  |94124  |B10      |42         |6495|3               |3       |3            |true   |null         |1        |MEDIC   |1                         |10                    |10                |Bayview Hunters Point|(37.7337623673897, -122.396113802632)|020110022-M17|4.7      |\n",
      "|20110023  |M41   |2003242       |Medical Incident|01/11/2002|01/10/2002|Other               |01/11/2002 02:39:50 AM|MARKET ST/MCALLISTER ST    |SF  |94102  |B03      |01         |1455|3               |3       |3            |true   |null         |1        |MEDIC   |2                         |3                     |6                 |Tenderloin           |(37.7811772186856, -122.411699931232)|020110023-M41|2.4333334|\n",
      "|20110032  |E11   |2003250       |Vehicle Fire    |01/11/2002|01/10/2002|Other               |01/11/2002 04:16:46 AM|APPLETON AV/MISSION ST     |SF  |94110  |B06      |32         |5626|3               |3       |3            |false  |null         |1        |ENGINE  |1                         |6                     |9                 |Bernal Heights       |(37.7388432849018, -122.423948785199)|020110032-E11|1.5      |\n",
      "|20110043  |B04   |2003259       |Alarms          |01/11/2002|01/10/2002|Other               |01/11/2002 06:01:58 AM|1400 Block of SUTTER ST    |SF  |94109  |B04      |03         |3223|3               |3       |3            |false  |null         |1        |CHIEF   |2                         |4                     |2                 |Western Addition     |(37.7872890372638, -122.424236212664)|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+----------------------+---------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------------+-------------------------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection / Projection\n",
    "\n",
    "- The process of selection is arguably the most fundamental means of reducing the footprint of the data you are working with.\n",
    "- This concept will be familiar to anyone with working knowledge of SQL.\n",
    "- In a nutshell, selection enables us to reduce the set of rows returned by a query by way of a condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+---------+\n",
      "|CallNumber|City|Delay    |\n",
      "+----------+----+---------+\n",
      "|20110016  |SF  |2.95     |\n",
      "|20110022  |SF  |4.7      |\n",
      "|20110023  |SF  |2.4333334|\n",
      "|20110032  |SF  |1.5      |\n",
      "|20110043  |SF  |3.4833333|\n",
      "+----------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.select(\"CallNumber\", \"City\", \"Delay\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+---------------------------+---------+---------+--------------------+\n",
      "|IncidentNumber|AvailableDtTm         |IncidentNumber|Address                    |NumAlarms|Battalion|CallFinalDisposition|\n",
      "+--------------+----------------------+--------------+---------------------------+---------+---------+--------------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|2003235       |2000 Block of CALIFORNIA ST|1        |B04      |Other               |\n",
      "|2003241       |01/11/2002 03:01:18 AM|2003241       |0 Block of SILVERVIEW DR   |1        |B10      |Other               |\n",
      "|2003242       |01/11/2002 02:39:50 AM|2003242       |MARKET ST/MCALLISTER ST    |1        |B03      |Other               |\n",
      "|2003250       |01/11/2002 04:16:46 AM|2003250       |APPLETON AV/MISSION ST     |1        |B06      |Other               |\n",
      "|2003259       |01/11/2002 06:01:58 AM|2003259       |1400 Block of SUTTER ST    |1        |B04      |Other               |\n",
      "+--------------+----------------------+--------------+---------------------------+---------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.select(\"IncidentNumber\", \"AvailableDtTm\", \"IncidentNumber\", \"Address\", \"NumAlarms\", \"Battalion\", \"CallFinalDisposition\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+---------------------------+---------+---------+--------------------+\n",
      "|IncidentNumber|AvailableDtTm         |IncidentNumber|Address                    |NumAlarms|Battalion|CallFinalDisposition|\n",
      "+--------------+----------------------+--------------+---------------------------+---------+---------+--------------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|2003235       |2000 Block of CALIFORNIA ST|1        |B04      |Other               |\n",
      "|2003241       |01/11/2002 03:01:18 AM|2003241       |0 Block of SILVERVIEW DR   |1        |B10      |Other               |\n",
      "|2003242       |01/11/2002 02:39:50 AM|2003242       |MARKET ST/MCALLISTER ST    |1        |B03      |Other               |\n",
      "|2003250       |01/11/2002 04:16:46 AM|2003250       |APPLETON AV/MISSION ST     |1        |B06      |Other               |\n",
      "|2003259       |01/11/2002 06:01:58 AM|2003259       |1400 Block of SUTTER ST    |1        |B04      |Other               |\n",
      "+--------------+----------------------+--------------+---------------------------+---------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.select(\"IncidentNumber\", \"AvailableDtTm\", \"IncidentNumber\", \"Address\", \"NumAlarms\", \"Battalion\", \"CallFinalDisposition\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection \n",
    "\n",
    "A projection in relational parlance is a way to return only the rows matching a certain relational condition by using filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Spark, projections are done with the select() method, while filters can be expressed using the filter() or where() method.\n",
    "- We can use this technique to examine specific aspects of our SF Fire Department data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Python\n",
    "few_fire_df = (fire_df\n",
    "      .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\") \\\n",
    "      .where(col(\"CallType\") != \"Medical Incident\"))\n",
    "few_fire_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a SQL View \n",
    "- A SQL View is a virtual table, which is based on SQL SELECT query.\n",
    "- A view contains rows and columns, just like a real table.\n",
    "- The fields in a view are fields from one or more real tables in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQL View\n",
    "fire_df.createOrReplaceTempView(\"fire_service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Alarms|\n",
      "+------+\n",
      "|1     |\n",
      "|3     |\n",
      "|5     |\n",
      "|4     |\n",
      "|2     |\n",
      "+------+\n",
      "\n",
      "+--------------------------------------------+\n",
      "|CallTypes                                   |\n",
      "+--------------------------------------------+\n",
      "|Elevator / Escalator Rescue                 |\n",
      "|Marine Fire                                 |\n",
      "|Aircraft Emergency                          |\n",
      "|Confined Space / Structure Collapse         |\n",
      "|Administrative                              |\n",
      "|Alarms                                      |\n",
      "|Odor (Strange / Unknown)                    |\n",
      "|Citizen Assist / Service Call               |\n",
      "|HazMat                                      |\n",
      "|Watercraft in Distress                      |\n",
      "|Explosion                                   |\n",
      "|Oil Spill                                   |\n",
      "|Vehicle Fire                                |\n",
      "|Suspicious Package                          |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "|Other                                       |\n",
      "|Outside Fire                                |\n",
      "|Traffic Collision                           |\n",
      "|Assist Police                               |\n",
      "|Gas Leak (Natural and LP Gases)             |\n",
      "+--------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the View to find the distinct number of alarms \n",
    "query = \"\"\"\n",
    "SELECT DISTINCT (NumAlarms) AS Alarms\n",
    "FROM fire_service\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)\n",
    "\n",
    "\n",
    "query1 = \"\"\"\n",
    "SELECT  DISTINCT (CallType) AS CallTypes\n",
    "FROM fire_service\n",
    "\"\"\"\n",
    "spark.sql(query1).show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+---------+\n",
      "|CallNumber|City|Delay    |\n",
      "+----------+----+---------+\n",
      "|20110016  |SF  |2.95     |\n",
      "|20110022  |SF  |4.7      |\n",
      "|20110023  |SF  |2.4333334|\n",
      "|20110032  |SF  |1.5      |\n",
      "|20110043  |SF  |3.4833333|\n",
      "+----------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the View\n",
    "query = \"\"\"\n",
    "SELECT CallNumber, City, Delay\n",
    "FROM fire_service\n",
    "WHERE City != 'San Francisco'\n",
    "\"\"\"\n",
    "spark.sql(query).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_fire_df = (fire_df.select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\") \\\n",
    "                             .where(col(\"CallType\") != \"Medical Incident\"))\n",
    "few_fire_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do some ETL:\n",
    "- Transform the string dates to Spark Timestamp data type so we can make some time-based queries later\n",
    "- Returns a transformed query\n",
    "- Cache the new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Change Data Type\n",
    "# check schema and locate the time columns \n",
    "fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------------------+\n",
      "|CallDate  |WatchDate |AvailableDtTm         |\n",
      "+----------+----------+----------------------+\n",
      "|01/11/2002|01/10/2002|01/11/2002 01:51:44 AM|\n",
      "|01/11/2002|01/10/2002|01/11/2002 03:01:18 AM|\n",
      "|01/11/2002|01/10/2002|01/11/2002 02:39:50 AM|\n",
      "|01/11/2002|01/10/2002|01/11/2002 04:16:46 AM|\n",
      "|01/11/2002|01/10/2002|01/11/2002 06:01:58 AM|\n",
      "+----------+----------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of time columns\n",
    "time_columns = [\n",
    "    'CallDate',\n",
    "    'WatchDate',\n",
    "    'AvailableDtTm'\n",
    "]\n",
    "\n",
    "# Select the time columns from the DataFrame\n",
    "time_columns_df = fire_df.select(*time_columns)\n",
    "\n",
    "# Show the result\n",
    "time_columns_df.show(5, truncate=False)\n",
    "\n",
    "# show the data types for the time columns\n",
    "time_columns_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Time Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTS      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert the string to timestamp format\n",
    "fire_ts_df = (fire_df.withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\")) \\\n",
    "                    .drop(\"CallDate\") \\\n",
    "                    .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\")) \\\n",
    "                    .drop(\"WatchDate\") \\\n",
    "                    .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"), \"MM/dd/yyyy hh:mm:ss a\")) \\\n",
    "                    .drop(\"AvailableDtTm\")\n",
    "                    )\n",
    "\n",
    "# Select the converted columns\n",
    "fire_ts_df.select(\"IncidentDate\", \"OnWatchDate\", \"AvailableDtTS\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CallNumber',\n",
       " 'UnitID',\n",
       " 'IncidentNumber',\n",
       " 'CallType',\n",
       " 'CallFinalDisposition',\n",
       " 'Address',\n",
       " 'City',\n",
       " 'Zipcode',\n",
       " 'Battalion',\n",
       " 'StationArea',\n",
       " 'Box',\n",
       " 'OriginalPriority',\n",
       " 'Priority',\n",
       " 'FinalPriority',\n",
       " 'ALSUnit',\n",
       " 'CallTypeGroup',\n",
       " 'NumAlarms',\n",
       " 'UnitType',\n",
       " 'UnitSequenceInCallDispatch',\n",
       " 'FirePreventionDistrict',\n",
       " 'SupervisorDistrict',\n",
       " 'Neighborhood',\n",
       " 'Location',\n",
       " 'RowID',\n",
       " 'Delay',\n",
       " 'IncidentDate',\n",
       " 'OnWatchDate',\n",
       " 'AvailableDtTS']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_ts_df.cache()\n",
    "fire_ts_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQL View\n",
    "fire_ts_df.createOrReplaceTempView(\"fire_services\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-1) How many distinct types of calls were made to the Fire Department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|30               |\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Execute your SQL query and create a DataFrame\n",
    "query = \"\"\"\n",
    "SELECT COUNT(DISTINCT CallType) AS DistinctCallTypes\n",
    "FROM fire_services\n",
    "WHERE CallType IS NOT NULL;\n",
    "\"\"\"\n",
    "result_df = spark.sql(query)\n",
    "result_df.show(truncate=False)\n",
    "\n",
    "# # Save the DataFrame as a table\n",
    "# result_df.createOrReplaceTempView(\"distinct_fire_calls\")\n",
    "\n",
    "# # Export the table as a Parquet file\n",
    "# result_df.write.mode(\"overwrite\").parquet(\"/path/to/output/common_fire_calls.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-2) What are distinct types of calls were made to the Fire Department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|DistinctCallTypes                           |\n",
      "+--------------------------------------------+\n",
      "|Elevator / Escalator Rescue                 |\n",
      "|Marine Fire                                 |\n",
      "|Aircraft Emergency                          |\n",
      "|Confined Space / Structure Collapse         |\n",
      "|Administrative                              |\n",
      "|Alarms                                      |\n",
      "|Odor (Strange / Unknown)                    |\n",
      "|Citizen Assist / Service Call               |\n",
      "|HazMat                                      |\n",
      "|Watercraft in Distress                      |\n",
      "|Explosion                                   |\n",
      "|Oil Spill                                   |\n",
      "|Vehicle Fire                                |\n",
      "|Suspicious Package                          |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "|Other                                       |\n",
      "|Outside Fire                                |\n",
      "|Traffic Collision                           |\n",
      "|Assist Police                               |\n",
      "|Gas Leak (Natural and LP Gases)             |\n",
      "+--------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute your SQL query and create a DataFrame\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT CallType AS DistinctCallTypes\n",
    "FROM fire_services\n",
    "WHERE CallType IS NOT NULL;\n",
    "\"\"\"\n",
    "result_df = spark.sql(query)\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-3) Find out all response or delayed times greater than 5 mins?\n",
    "- Rename the column Delay - > ReponseDelayedinMins.\n",
    "- Returns a new DataFrame.\n",
    "- Find out all calls where the response time to the fire site was delayed for more than 5 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|ResponseDelayedinMins|\n",
      "+---------------------+\n",
      "|5.35                 |\n",
      "|6.25                 |\n",
      "|5.2                  |\n",
      "|5.6                  |\n",
      "|7.25                 |\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "renamed_fire_df = fire_ts_df.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "renamed_fire_df \\\n",
    "        .select(\"ResponseDelayedinMins\") \\\n",
    "        .where(col(\"ResponseDelayedinMins\") > 5) \\\n",
    "        .show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-4) What were all the different types of fire calls in 2018?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|CallType                       |\n",
      "+-------------------------------+\n",
      "|Elevator / Escalator Rescue    |\n",
      "|Alarms                         |\n",
      "|Odor (Strange / Unknown)       |\n",
      "|Citizen Assist / Service Call  |\n",
      "|HazMat                         |\n",
      "|Explosion                      |\n",
      "|Vehicle Fire                   |\n",
      "|Suspicious Package             |\n",
      "|Other                          |\n",
      "|Outside Fire                   |\n",
      "|Traffic Collision              |\n",
      "|Assist Police                  |\n",
      "|Gas Leak (Natural and LP Gases)|\n",
      "|Water Rescue                   |\n",
      "|Electrical Hazard              |\n",
      "|Structure Fire                 |\n",
      "|Medical Incident               |\n",
      "|Fuel Spill                     |\n",
      "|Smoke Investigation (Outside)  |\n",
      "|Train / Rail Incident          |\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT CallType\n",
    "FROM fire_services\n",
    "WHERE EXTRACT(YEAR FROM IncidentDate) = 2018;\n",
    "\"\"\"\n",
    "spark.sql(query).show( truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-5) What are the most common types of fire calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+---------+\n",
      "|CallType                       |CallCount|\n",
      "+-------------------------------+---------+\n",
      "|Medical Incident               |113794   |\n",
      "|Structure Fire                 |23319    |\n",
      "|Alarms                         |19406    |\n",
      "|Traffic Collision              |7013     |\n",
      "|Citizen Assist / Service Call  |2524     |\n",
      "|Other                          |2166     |\n",
      "|Outside Fire                   |2094     |\n",
      "|Vehicle Fire                   |854      |\n",
      "|Gas Leak (Natural and LP Gases)|764      |\n",
      "|Water Rescue                   |755      |\n",
      "|Odor (Strange / Unknown)       |490      |\n",
      "|Electrical Hazard              |482      |\n",
      "|Elevator / Escalator Rescue    |453      |\n",
      "|Smoke Investigation (Outside)  |391      |\n",
      "|Fuel Spill                     |193      |\n",
      "|HazMat                         |124      |\n",
      "|Industrial Accidents           |94       |\n",
      "|Explosion                      |89       |\n",
      "|Train / Rail Incident          |57       |\n",
      "|Aircraft Emergency             |36       |\n",
      "+-------------------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the View\n",
    "query = \"\"\"\n",
    "\n",
    "SELECT CallType, COUNT(*) AS CallCount\n",
    "FROM fire_service\n",
    "WHERE CallType IS NOT NULL\n",
    "GROUP BY CallType\n",
    "ORDER BY CallCount DESC;\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-6) What were the most common call types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------+\n",
      "|CallType                       |count |\n",
      "+-------------------------------+------+\n",
      "|Medical Incident               |113794|\n",
      "|Structure Fire                 |23319 |\n",
      "|Alarms                         |19406 |\n",
      "|Traffic Collision              |7013  |\n",
      "|Citizen Assist / Service Call  |2524  |\n",
      "|Other                          |2166  |\n",
      "|Outside Fire                   |2094  |\n",
      "|Vehicle Fire                   |854   |\n",
      "|Gas Leak (Natural and LP Gases)|764   |\n",
      "|Water Rescue                   |755   |\n",
      "+-------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    " .select(\"CallType\").where(col(\"CallType\").isNotNull())\n",
    " .groupBy(\"CallType\")\n",
    " .count()\n",
    " .orderBy(\"count\", ascending=False)\n",
    " .show(n=10, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-6A) What zip codes accounted for most common calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+---------+\n",
      "|CallType        |ZipCode|CallCount|\n",
      "+----------------+-------+---------+\n",
      "|Medical Incident|94102  |16130    |\n",
      "|Medical Incident|94103  |14775    |\n",
      "|Medical Incident|94110  |9995     |\n",
      "|Medical Incident|94109  |9479     |\n",
      "|Medical Incident|94124  |5885     |\n",
      "|Medical Incident|94112  |5630     |\n",
      "|Medical Incident|94115  |4785     |\n",
      "|Medical Incident|94122  |4323     |\n",
      "|Medical Incident|94107  |4284     |\n",
      "|Medical Incident|94133  |3977     |\n",
      "|Medical Incident|94117  |3522     |\n",
      "|Medical Incident|94134  |3437     |\n",
      "|Medical Incident|94114  |3225     |\n",
      "|Medical Incident|94118  |3104     |\n",
      "|Medical Incident|94121  |2953     |\n",
      "|Medical Incident|94116  |2738     |\n",
      "|Medical Incident|94132  |2594     |\n",
      "|Structure Fire  |94110  |2267     |\n",
      "|Medical Incident|94105  |2258     |\n",
      "|Structure Fire  |94102  |2229     |\n",
      "+----------------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the View\n",
    "query = \"\"\"\n",
    "SELECT CallType, ZipCode, COUNT(*) AS CallCount\n",
    "FROM fire_services\n",
    "WHERE CallType IS NOT NULL\n",
    "GROUP BY CallType, ZipCode\n",
    "ORDER BY CallCount DESC;\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-6B) What San Francisco neighborhoods are in the zip codes 94102 and 94103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|Neighborhood                  |\n",
      "+------------------------------+\n",
      "|Western Addition              |\n",
      "|Mission Bay                   |\n",
      "|Hayes Valley                  |\n",
      "|Financial District/South Beach|\n",
      "|Nob Hill                      |\n",
      "|Mission                       |\n",
      "|Tenderloin                    |\n",
      "|Potrero Hill                  |\n",
      "|Castro/Upper Market           |\n",
      "|South of Market               |\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the View\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT Neighborhood\n",
    "FROM fire_services\n",
    "WHERE ZipCode IN ('94102', '94103');\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q-6a) How many distinct years of data is in the CSV file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|DistinctYears|\n",
      "+-------------+\n",
      "|19           |\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the View\n",
    "query = \"\"\"\n",
    "SELECT COUNT(DISTINCT EXTRACT(YEAR FROM IncidentDate)) AS DistinctYears\n",
    "FROM fire_services;\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|DistinctYears|\n",
      "+-------------+\n",
      "|2000         |\n",
      "|2001         |\n",
      "|2002         |\n",
      "|2003         |\n",
      "|2004         |\n",
      "|2005         |\n",
      "|2006         |\n",
      "|2007         |\n",
      "|2008         |\n",
      "|2009         |\n",
      "|2010         |\n",
      "|2011         |\n",
      "|2012         |\n",
      "|2013         |\n",
      "|2014         |\n",
      "|2015         |\n",
      "|2016         |\n",
      "|2017         |\n",
      "|2018         |\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the View\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT EXTRACT(YEAR FROM IncidentDate) AS DistinctYears\n",
    "FROM fire_services\n",
    "ORDER BY DistinctYears;\n",
    "\"\"\"\n",
    "spark.sql(query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-6b) What week of the year in 2018 had the most fire calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|weekofyear(IncidentDate)|count|\n",
      "+------------------------+-----+\n",
      "|                      22|  259|\n",
      "|                      40|  255|\n",
      "|                      43|  250|\n",
      "|                      25|  249|\n",
      "|                       1|  246|\n",
      "|                      44|  244|\n",
      "|                      13|  243|\n",
      "|                      32|  243|\n",
      "|                      11|  240|\n",
      "|                       5|  236|\n",
      "|                      18|  236|\n",
      "|                      23|  235|\n",
      "|                      42|  234|\n",
      "|                       2|  234|\n",
      "|                      31|  234|\n",
      "|                      19|  233|\n",
      "|                      10|  232|\n",
      "|                      34|  232|\n",
      "|                       8|  232|\n",
      "|                      28|  231|\n",
      "+------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_ts_df.filter(year('IncidentDate') == 2018) \\\n",
    "        .groupBy(weekofyear('IncidentDate')) \\\n",
    "                    .count() \\\n",
    "                        .orderBy('count', ascending=False) \\\n",
    "                                            .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "null_entries_df = fire_df.filter(F.col('CallNumber').isNull() | \\\n",
    "                                 F.col('UnitID').isNull() | \\\n",
    "                                 F.col('IncidentNumber').isNull() | \\\n",
    "                                 F.col('CallType').isNull() | \\\n",
    "                                 F.col('CallDate').isNull() | \\\n",
    "                                 F.col('WatchDate').isNull() | \\\n",
    "                                 F.col('CallFinalDisposition').isNull() | \\\n",
    "                                 F.col('AvailableDtTm').isNull() | \\\n",
    "                                 F.col('Address').isNull() | \\\n",
    "                                 F.col('City').isNull() | \\\n",
    "                                 F.col('Zipcode').isNull() | \\\n",
    "                                 F.col('Battalion').isNull() | \\\n",
    "                                 F.col('StationArea').isNull() | \\\n",
    "                                 F.col('Box').isNull() | \\\n",
    "                                 F.col('OriginalPriority').isNull() | \\\n",
    "                                 F.col('Priority').isNull() | \\\n",
    "                                 F.col('FinalPriority').isNull() | \\\n",
    "                                 F.col('ALSUnit').isNull() | \\\n",
    "                                 F.col('CallTypeGroup').isNull() | \\\n",
    "                                 F.col('NumAlarms').isNull() | \\\n",
    "                                 F.col('UnitType').isNull() | \\\n",
    "                                 F.col('UnitSequenceInCallDispatch').isNull() | \\\n",
    "                                 F.col('FirePreventionDistrict').isNull() | \\\n",
    "                                 F.col('SupervisorDistrict').isNull() | \\\n",
    "                                 F.col('Neighborhood').isNull() | \\\n",
    "                                 F.col('Location').isNull() | \\\n",
    "                                 F.col('RowID').isNull() | \\\n",
    "                                 F.col('Delay').isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100992"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_entries_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74304"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "not_null_entries_df = fire_df.filter(\n",
    "    ~F.col('CallNumber').isNull() &\n",
    "    ~F.col('UnitID').isNull() &\n",
    "    ~F.col('IncidentNumber').isNull() &\n",
    "    ~F.col('CallType').isNull() &\n",
    "    ~F.col('CallDate').isNull() &\n",
    "    ~F.col('WatchDate').isNull() &\n",
    "    ~F.col('CallFinalDisposition').isNull() &\n",
    "    ~F.col('AvailableDtTm').isNull() &\n",
    "    ~F.col('Address').isNull() &\n",
    "    ~F.col('City').isNull() &\n",
    "    ~F.col('Zipcode').isNull() &\n",
    "    ~F.col('Battalion').isNull() &\n",
    "    ~F.col('StationArea').isNull() &\n",
    "    ~F.col('Box').isNull() &\n",
    "    ~F.col('OriginalPriority').isNull() &\n",
    "    ~F.col('Priority').isNull() &\n",
    "    ~F.col('FinalPriority').isNull() &\n",
    "    ~F.col('ALSUnit').isNull() &\n",
    "    ~F.col('CallTypeGroup').isNull() &\n",
    "    ~F.col('NumAlarms').isNull() &\n",
    "    ~F.col('UnitType').isNull() &\n",
    "    ~F.col('UnitSequenceInCallDispatch').isNull() &\n",
    "    ~F.col('FirePreventionDistrict').isNull() &\n",
    "    ~F.col('SupervisorDistrict').isNull() &\n",
    "    ~F.col('Neighborhood').isNull() &\n",
    "    ~F.col('Location').isNull() &\n",
    "    ~F.col('RowID').isNull() &\n",
    "    ~F.col('Delay').isNull()\n",
    ")\n",
    "not_null_entries_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Columns: 175296\n",
      "Count of Nulls: 100992\n",
      "Count of Not Nulls: 74304\n",
      "The columns count is correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "total_columns = fire_df.count()\n",
    "count_nulls = null_entries_df.count()\n",
    "count_not_nulls = not_null_entries_df.count()\n",
    "\n",
    "if count_nulls + count_not_nulls == total_columns:\n",
    "    print(f\"Total Columns: {total_columns}\")\n",
    "    print(f\"Count of Nulls: {count_nulls}\")\n",
    "    print(f\"Count of Not Nulls: {count_not_nulls}\")\n",
    "    print(\"The columns count is correct\")\n",
    "else:\n",
    "    print(\"Counts do not add up to the total number of columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/Users/oasis/Desktop/learn-spark/parq_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# write the data to parquet file\n",
    "fire_df.write.format(\"parquet\").mode(\"overwrite\").save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=====>                                                   (1 + 10) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# write the data from parquet file\n",
    "today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "output_path = f\"{output_path}/{today_date}_curated\"\n",
    "\n",
    "fire_df.write.option(\"compression\", \"snappy\").parquet(output_path)\n",
    "print(\"Data written successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
